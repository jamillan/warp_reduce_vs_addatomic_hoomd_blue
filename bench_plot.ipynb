{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os \n",
      "import sys \n",
      "import json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_path = os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_warp = cur_path + \"/\" + \"warp_reduce\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_addatomic = cur_path + \"/\" + \"addatomic\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create paths to warp reduce dirctories/metadata\n",
      "#name of directories\n",
      "n_par = os.listdir(path_warp)\n",
      "\n",
      "warp_paths = []\n",
      "for _p in n_par:\n",
      "    new_path = path_warp + \"/\" + str(_p)\n",
      "    warp_paths.append(new_path)\n",
      "    \n",
      "#print path for sanity check\n",
      "print(warp_paths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['54000_par', '250000_par', '2000_par', '500000_par']\n",
        "['/home/jaime/Desktop/Wall_Test/warp_reduce/54000_par', '/home/jaime/Desktop/Wall_Test/warp_reduce/250000_par', '/home/jaime/Desktop/Wall_Test/warp_reduce/2000_par', '/home/jaime/Desktop/Wall_Test/warp_reduce/500000_par']\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create paths to add atomic dirctories/metadata\n",
      "#name of directories\n",
      "n_par = os.listdir(path_warp)\n",
      "\n",
      "#add path to buffer list\n",
      "addatomic_paths = []\n",
      "for _p in n_par:\n",
      "    new_path = path_addatomic + \"/\" + str(_p)\n",
      "    addatomic_paths.append(new_path)\n",
      "    \n",
      "#print path for sanity check    \n",
      "print(addatomic_paths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/home/jaime/Desktop/Wall_Test/addatomic/54000_par', '/home/jaime/Desktop/Wall_Test/addatomic/250000_par', '/home/jaime/Desktop/Wall_Test/addatomic/2000_par', '/home/jaime/Desktop/Wall_Test/addatomic/500000_par']\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#get the metadata for the warp computes\n",
      "\n",
      "warp_pts =[]\n",
      "warp_nbr_particles = []\n",
      "\n",
      "#hash data so we can organize it\n",
      "warp_hash= {}\n",
      "\n",
      "for idx,_path in enumerate(warp_paths[:3]):\n",
      "    \n",
      "    #read file\n",
      "    df = open(_path + \"/\" + \"metadata.json\", \"r\")\n",
      "    df = json.load(df)\n",
      "    #get keys\n",
      "    df_keys = df.keys();\n",
      "    #print(df_keys)\n",
      "    _pts = df['user']['tps']\n",
      "    _pts = np.array(_pts)\n",
      "    warp_pts.append(np.mean(_pts))\n",
      "    #get number of particles\n",
      "    N=df['hoomd.data.system_data']['particles']['N']\n",
      "    #hsh data\n",
      "    warp_hash[N] = warp_pts[idx] * N\n",
      "    warp_nbr_particles.append(int(d))\n",
      "  \n",
      "    \n",
      "# hash organize data for plotting\n",
      "warp_bmark = {}\n",
      "for key in sorted(warp_hash.iterkeys()):\n",
      "    print \"%s: %s\" % (key, warp_hash[key])\n",
      "    warp_bmark[key]= warp_hash[key]\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2000: 12681440.6738\n",
        "54000: 23816937.4695\n",
        "250000: 10345644.474\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "[12681440.673828125, 23816937.469482422, 10345644.474029541]"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#of get the metadata for the addtomic computes\n",
      "\n",
      "addatomic_pts =[]\n",
      "addatomic_nbr_particles = []\n",
      "addatomic_hash= {}\n",
      "\n",
      "for idx,_path in enumerate(addatomic_paths[:3]):\n",
      "    \n",
      "    #read file\n",
      "    df = open(_path + \"/\" + \"metadata.json\", \"r\")\n",
      "    df = json.load(df)\n",
      "    #get keys\n",
      "    df_keys = df.keys();\n",
      "    #get pts\n",
      "    _pts = df['user']['tps']\n",
      "    _pts = np.array(_pts)\n",
      "    \n",
      "    addatomic_pts.append(np.mean(_pts))\n",
      "    #get number of particles\n",
      "    N=df['hoomd.data.system_data']['particles']['N']\n",
      "    addatomic_hash[N] = addatomic_pts[idx] * N\n",
      "    addatomic_nbr_particles.append(float(d))\n",
      "    \n",
      "# hash organize data for plotting\n",
      "addatomic_bmark = {}\n",
      "for key in sorted(addatomic_hash.iterkeys()):\n",
      "    print \"%s: %s\" % (key, addatomic_hash[key])\n",
      "    addatomic_bmark[key]= addatomic_hash[key]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2000: 11039678.2227\n",
        "54000: 17136655.1971\n",
        "250000: 9447049.61777\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot benmarks : Number of particles vs PTS * number of particles\n",
      "\n",
      "figure= plt.figure(figsize=(10,10))\n",
      "plt.plot(addatomic_bmark.keys(),addatomic_bmark.values(),\"o\",color='b',markersize=8)\n",
      "plt.hold(True)\n",
      "plt.plot(addatomic_bmark.keys(),addatomic_bmark.values(),\"-\",label ='addAtomic',linewidth=2)\n",
      "plt.hold(True)\n",
      "plt.plot(warp_bmark.keys(),warp_bmark.values(),\"o\",color='r',markersize=8)\n",
      "plt.hold(True)\n",
      "plt.plot(warp_bmark.keys(),warp_bmark.values(),\"-\",color='r',label = 'Warp Reduce',linewidth=2)\n",
      "plt.hold(True)\n",
      "plt.legend()\n",
      "plt.xlabel(\"Number of Particles\")\n",
      "plt.ylabel(\"mean TPS * Number of Particles\")\n",
      "plt.xlim(100,300000)\n",
      "plt.savefig('warp_reduce_vs_addatomic.png')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}